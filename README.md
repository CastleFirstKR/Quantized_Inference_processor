## Quantized Inference processor For Custom CNN model 
### (Conv layer : 2 , MLP layer : 2)


### Weight Quantization => Binary Multiply Method (0.22 -> 0.22 * 32 = ~7)
